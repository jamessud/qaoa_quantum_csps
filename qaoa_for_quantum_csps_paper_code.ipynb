{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#change cupy to numpy if cupy not installed\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credit arxiv 1910.08187\n",
    "sk_angles = pickle.load(open(\"data/sk_angles.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretch_array(arr, new_length):\n",
    "    old_length = len(arr)\n",
    "    if old_length == new_length:\n",
    "        return arr  # No change needed\n",
    "    \n",
    "    # Create an array of new indices\n",
    "    new_indices = np.linspace(0, old_length - 1, new_length)\n",
    "    \n",
    "    # Interpolate values\n",
    "    stretched_array = np.interp(new_indices, np.arange(old_length), arr)\n",
    "    \n",
    "    return stretched_array\n",
    "\n",
    "\n",
    "def gen_all_bitstrings(bs_size):\n",
    "    arrays = [[-1, 1]] * bs_size\n",
    "    mesh = np.meshgrid(*arrays)\n",
    "    return np.stack(mesh, axis=-1).reshape(-1, bs_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compact Iterations at $D\\rightarrow \\infty$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing Ansatze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $MC$ Ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_z_idx(p, idx): # assuming a is indexed as 1,2,3...p,0,-p,...-1, find index of idx in a\n",
    "    return (idx>0)*(idx-1) + (idx==0)*p + (idx<0)*(2*p+idx+1) \n",
    "\n",
    "def get_mc_eib_entries(bit1, bit2, beta):    \n",
    "    return np.cos(beta)**(np.abs(bit1+bit2)/2) * (1j * np.sin(beta))**(np.abs(bit1-bit2)/2)\n",
    "\n",
    "def get_mc_f_beta(p, bs, beta, get_f_prime=False):\n",
    "    bs_size = 2*p+1\n",
    "    all_beta = np.concatenate((beta, np.array([-beta_j for beta_j in beta[::-1]])))\n",
    "    prod = 0.5 * np.ones(len(bs), dtype='complex')\n",
    "    for j in range(bs_size-1):\n",
    "        if j==p-1 and get_f_prime:\n",
    "            prod *= get_mc_eib_entries(bs[:,j], -bs[:,j+1], all_beta[j])\n",
    "        else:\n",
    "            prod *= get_mc_eib_entries(bs[:,j], bs[:,j+1], all_beta[j]) \n",
    "    return prod\n",
    "\n",
    "def get_B0(p):\n",
    "    half = np.array(list(product(np.array([1,-1]), repeat=p+1)))\n",
    "    return np.hstack((half, np.flip(half,axis=1)[:,1:]))\n",
    "\n",
    "def get_ta(p, bs):\n",
    "    ta = 0\n",
    "    for r in range(1,p+1):\n",
    "        r_idx, nr_idx = get_z_idx(p, r), get_z_idx(p, -r)\n",
    "        if bs[r_idx] != bs[nr_idx]:\n",
    "            ta = r\n",
    "    return ta\n",
    "\n",
    "def get_all_ta_leq_m(p, m):\n",
    "    left = np.array(list(product(np.array([1,-1]), repeat=m)))\n",
    "    right = np.array(list(product(np.array([1,-1]), repeat=m)))\n",
    "    middle_half = np.array(list(product(np.array([1,-1]), repeat=p-m+1)))\n",
    "    middle = np.hstack((middle_half, np.flip(middle_half,axis=1)[:,1:]))\n",
    "    # Create meshgrids for indices\n",
    "    left_idx, middle_idx, right_idx = np.meshgrid(np.arange(left.shape[0]),\n",
    "                                                np.arange(middle.shape[0]),\n",
    "                                                np.arange(right.shape[0]), indexing='ij')\n",
    "    # Combine indices to get all possible combinations\n",
    "    result = np.column_stack((left[left_idx.ravel()], middle[middle_idx.ravel()], right[right_idx.ravel()]))\n",
    "\n",
    "    return result\n",
    "\n",
    "def get_Hm_a(p, a, ta, gamma, G_prev):\n",
    "    exp_sum_1, exp_sum_2 = 0, 0 \n",
    "    for sp in range(1, ta+1):\n",
    "        sp_idx, nsp_idx = get_z_idx(p, sp), get_z_idx(p, -sp)\n",
    "        exp_sum_1 += gamma[sp_idx]**2 * (1-a[sp_idx]*a[nsp_idx])\n",
    "        for rp in range(1, sp):\n",
    "            rp_idx, nrp_idx = get_z_idx(p, rp), get_z_idx(p, -rp)\n",
    "            exp_sum_2 += gamma[sp_idx] * gamma[rp_idx] * (G_prev[rp_idx, sp_idx]*a[rp_idx]-np.conjugate(G_prev[rp_idx, sp_idx])*a[nrp_idx]) * (a[sp_idx]-a[nsp_idx])\n",
    "    return np.exp(-exp_sum_1 - exp_sum_2)\n",
    "\n",
    "\n",
    "def get_Hm_a_vectorized(p, as_array, tas, gamma, G_prev):\n",
    "    exp_sum_1 = np.zeros(as_array.shape[0], dtype='complex')  # Use complex zeros\n",
    "    exp_sum_2 = np.zeros(as_array.shape[0], dtype='complex')  # Use complex zeros\n",
    "\n",
    "    for sp in range(1, np.max(tas) + 1):  # Loop over sp values\n",
    "        sp_idx = get_z_idx(p, sp)  # Get the index for positive sp\n",
    "        nsp_idx = get_z_idx(p, -sp)  # Get the index for negative sp\n",
    "\n",
    "        # Determine which indices to consider based on tas\n",
    "        valid_indices = tas >= sp\n",
    "\n",
    "        # Compute contributions to exp_sum_1 and exp_sum_2\n",
    "        exp_sum_1[valid_indices] += gamma[sp_idx]**2 * (1 - as_array[valid_indices, sp_idx] * as_array[valid_indices, nsp_idx])\n",
    "\n",
    "        for rp in range(1, sp):  # Loop over rp values\n",
    "            rp_idx = get_z_idx(p, rp)  # Get the index for positive rp\n",
    "            nrp_idx = get_z_idx(p, -rp)  # Get the index for negative rp\n",
    "            \n",
    "            exp_sum_2[valid_indices] += (gamma[sp_idx] * gamma[rp_idx] * \n",
    "                (G_prev[rp_idx, sp_idx] * as_array[valid_indices, rp_idx] -\n",
    "                np.conjugate(G_prev[rp_idx, sp_idx]) * as_array[valid_indices, nrp_idx]) *\n",
    "                (as_array[valid_indices, sp_idx] - as_array[valid_indices, nsp_idx]))\n",
    "\n",
    "    return np.exp(-exp_sum_1 - exp_sum_2)  # Return the result as an array\n",
    "\n",
    "\n",
    "\n",
    "def get_mc_nu(p, gamma, beta, bitstrings, ta, separate=False):\n",
    "\n",
    "    bs_size=2*p+1\n",
    "    # Initialize matrices\n",
    "    G_prev = np.eye(bs_size, dtype='complex') + np.flip(np.eye(bs_size, dtype='complex'), axis=1)\n",
    "    G_curr = np.eye(bs_size, dtype='complex') + np.flip(np.eye(bs_size, dtype='complex'), axis=1)\n",
    "    G_prev[p, p], G_curr[p, p] = 1, 1\n",
    "    G_prime_0 = np.zeros(p, dtype='complex')\n",
    "    # Precompute fas and fpas\n",
    "    fas = get_mc_f_beta(p, bitstrings, beta)\n",
    "    fpas = get_mc_f_beta(p, bitstrings, beta, get_f_prime=True)\n",
    "    for m in range(1, p + 1):\n",
    "        m_idx = get_z_idx(p, m)\n",
    "        valid_indices = np.where(ta <= m)[0]  \n",
    "\n",
    "        if valid_indices.size > 0:\n",
    "            valid_bitstrings = bitstrings[valid_indices]\n",
    "            fa_valid = fas[valid_indices]\n",
    "            fpa_valid = fpas[valid_indices]\n",
    "            ta_valid = ta[valid_indices]\n",
    "            # Compute Hma for all valid bitstrings in a vectorized manner\n",
    "            # Use a vectorized implementation of get_Hm_a if possible.\n",
    "            #Hma = np.array([get_Hm_a(p, a, int(ta_i), gamma, G_prev) for a, ta_i in zip(valid_bitstrings, ta_valid)])\n",
    "            Hma = get_Hm_a_vectorized(p, valid_bitstrings, ta_valid, gamma, G_prev)\n",
    "            # Use broadcasting to compute contributions in a vectorized manner\n",
    "            for r in range(1, m + 1):\n",
    "                r_idx = get_z_idx(p, r)\n",
    "                if m <= p - 1:\n",
    "                    # This computation may be done more efficiently with broadcasting\n",
    "                    G_curr[r_idx, m_idx + 1] += np.sum(fa_valid * Hma * valid_bitstrings[:, r_idx] * valid_bitstrings[:, m_idx + 1])\n",
    "                else:\n",
    "                    zero_idx = get_z_idx(p, 0)\n",
    "                    G_curr[zero_idx, r_idx] += np.sum(fa_valid * Hma * valid_bitstrings[:, zero_idx] * valid_bitstrings[:, r_idx])\n",
    "                    G_prime_0[r_idx] += np.sum(fpa_valid * Hma * valid_bitstrings[:, zero_idx] * valid_bitstrings[:, r_idx])\n",
    "\n",
    "        if m <= p - 1:\n",
    "            G_prev = G_curr\n",
    "    nu_y, nu_z = 0, 0 \n",
    "    for r in range(1,p+1):\n",
    "        r_idx, zero_idx = get_z_idx(p, r), get_z_idx(p, 0)\n",
    "        nu_y += (-1j/2) * gamma[r_idx] * ((G_prime_0[r_idx])**2 - np.conjugate(G_prime_0[r_idx])**2)\n",
    "        nu_z += (1j/2) * gamma[r_idx] * ((G_curr[zero_idx, r_idx])**2 - np.conjugate(G_curr[zero_idx, r_idx])**2)\t\t\n",
    "\n",
    "    if separate: \n",
    "        return np.real(nu_y), np.real(nu_z)\n",
    "    else:\n",
    "        return np.real(nu_y + nu_z)\n",
    "    return\n",
    "\n",
    "\n",
    "def get_mc_nu_helper(p, separate=False, negate=False): \n",
    "    # in order to optimize over params\n",
    "    bs_size = 2*p+1\n",
    "    bitstrings = gen_all_bitstrings(bs_size)\n",
    "    # Pre-compute ta for all bitstrings\n",
    "    ta = np.array([get_ta(p, a) for a in bitstrings])\n",
    "    def get_expectation(params):\n",
    "        gamma = params[:p]\n",
    "        beta = params[p:]\n",
    "        return (1-2*negate)*get_mc_nu(p, gamma, beta, bitstrings, ta, separate=separate)\n",
    "\n",
    "    return get_expectation\n",
    "\n",
    "def get_mc_nu_last_gamma_helper(p, gamma_pm1, beta_pm1, separate=False, negate=False): \n",
    "    # in order to optimize over params assuming all but last gamma is fixed\n",
    "    # input length p-1 gamma and length p-1 beta (last beta will be set to 0)\n",
    "    bs_size = 2*p+1\n",
    "    bitstrings = gen_all_bitstrings(bs_size)\n",
    "    # Pre-compute ta for all bitstrings\n",
    "    ta = np.array([get_ta(p, a) for a in bitstrings])\n",
    "\n",
    "    def get_expectation(last_gamma):\n",
    "        gamma = np.concatenate((gamma_pm1, last_gamma))\n",
    "        beta = np.concatenate((beta_pm1, np.zeros(1)))\n",
    "        return (1-2*negate)*get_mc_nu(p, gamma, beta, bitstrings, ta, separate=separate)\n",
    "\n",
    "    return get_expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $XY$ ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers\n",
    "def get_xy_h_i(y, z):\n",
    "    # inner product <y|z>\n",
    "    return 1j**((-y+y*z)/2) / np.sqrt(2)\n",
    "\n",
    "def get_xy_g_i(y, z, beta):\n",
    "    # inner product <y|e^{i beta X}|z>\n",
    "    return get_xy_h_i(y,z) * (np.cos(beta) + (-1)**((y*z-1)/2)*np.sin(beta))\n",
    "\n",
    "def get_xy_f(p, bitstrings, beta, f_prime=False): # length 2^(4p+1) vector storing result for all a\n",
    "    # bitstrings,[j,:] indexed as a_1, a_2, ..., a_p, a_0, a_{-p}, .... a_{-1}\n",
    "    tot = 1/2 * np.ones(2**(4*p+1)).astype('complex')\n",
    "    for l in range(p):\n",
    "        tot *= np.conjugate(get_xy_h_i(bitstrings[:,2*l+1], bitstrings[:,2*l])) #<z_l|y_l>\n",
    "        if f_prime and l==(p-1):\n",
    "            tot *= get_xy_g_i(bitstrings[:,2*l+1], -bitstrings[:,2*l+2], beta[l]) #<y_l|e^{i beta_l X}|z_{l+1}> (or z_0 if l=p)\n",
    "        else:\n",
    "            tot *= get_xy_g_i(bitstrings[:,2*l+1], bitstrings[:,2*l+2], beta[l]) #<y_l|e^{i beta_l X}|z_{l+1}> (or z_0 if l=p)\n",
    "        tot *= get_xy_h_i(bitstrings[:,-(2*l+2)], bitstrings[:,-(2*l+1)])  #<y_{-l}|z_{-l}>\n",
    "        tot *= np.conjugate(get_xy_g_i(bitstrings[:,-(2*l+2)], bitstrings[:,-(2*l+3)], beta[l])) #<z_{-(l+1)}|e^{-i beta_l X}|y_{-l}>\n",
    "    return tot\n",
    "\n",
    "\n",
    "def get_xy_G2pm1(p, bitstrings, f_a, Gamma_vec, beta):\n",
    "    # gets G^(2p-1)\n",
    "\n",
    "    # Initialize G^(0)\n",
    "    new_G = np.zeros((4 * p + 1, 4 * p + 1), dtype='complex')\n",
    "    \n",
    "    # Precompute Gamma_vec outer product\n",
    "    Gamma_outer = np.outer(Gamma_vec, Gamma_vec)\n",
    "\n",
    "    for m in range(2 * p):\n",
    "        prev_G = new_G.copy()\n",
    "        new_G.fill(0)  # Reset new_G to zero\n",
    "        # Compute a_outer products for all bitstrings\n",
    "        a_outer = bitstrings[:, :, np.newaxis] * bitstrings[:, np.newaxis, :]\n",
    "        # Efficient computation of exp_sums\n",
    "        exp_sums = np.einsum('ijk,jk->i', a_outer, Gamma_outer * prev_G)\n",
    "        # Compute exp_factors\n",
    "        exp_factors = np.exp(-0.5 * exp_sums)\n",
    "        # Vectorized update of new_G\n",
    "        new_G += np.tensordot(f_a * exp_factors, a_outer, axes=(0, 0))\n",
    "\n",
    "    return new_G\n",
    "\n",
    "\n",
    "def get_xy_H2p(p, bitstrings, Gamma_vec, G2pm1):\n",
    "\n",
    "    # Precompute Gamma outer product\n",
    "    Gamma_outer = np.outer(Gamma_vec, Gamma_vec)\n",
    "    # Compute the term (Gamma_outer * G2pm1) which is constant\n",
    "    Gamma_G = Gamma_outer * G2pm1\n",
    "    # Compute the outer product of bitstrings\n",
    "    a_outer = bitstrings[:, :, np.newaxis] * bitstrings[:, np.newaxis, :]\n",
    "    # Compute exp_sums using broadcasting and summing over the appropriate axes\n",
    "    exp_sums = np.sum(a_outer * Gamma_G, axis=(1, 2))\n",
    "    # Compute H2p\n",
    "    H2p = np.exp(-0.5 * exp_sums)\n",
    "    return H2p\n",
    "\n",
    "def get_xy_nu(p, gamma_y, gamma_z, beta, bitstrings, separate=False):\n",
    "\n",
    "    Gamma_vec = np.zeros(4*p+1)\n",
    "    Gamma_vec[:2*p:2]=gamma_z\n",
    "    Gamma_vec[1:2*p:2]=gamma_y\n",
    "    Gamma_vec[4*p-1:2*p:-2]=-gamma_y\n",
    "    Gamma_vec[4*p:2*p:-2]=-gamma_z\n",
    "\n",
    "    f_a = get_xy_f(p, bitstrings, beta)\n",
    "    fp_a = get_xy_f(p, bitstrings, beta, f_prime=True)\n",
    "    G2pm1 = get_xy_G2pm1(p, bitstrings, f_a, Gamma_vec, beta) # get G^(2p-1)\n",
    "    H2p = get_xy_H2p(p, bitstrings, Gamma_vec, G2pm1) # get H^(2p)\n",
    "\n",
    "    f_H2p = f_a * H2p\n",
    "    fp_H2p = fp_a * H2p\n",
    "\n",
    "    # Vectorize the computation of y_tot and z_tot\n",
    "    # Shape: (len(bitstrings), 4*p+1)\n",
    "    y_tot_mat = (fp_H2p[:, np.newaxis] * bitstrings[:, [2*p]] * bitstrings)\n",
    "    z_tot_mat = (f_H2p[:, np.newaxis] * bitstrings[:, [2*p]] * bitstrings)\n",
    "\n",
    "    # Compute the sums for y_tot and z_tot across a_idx (axis 0)\n",
    "    y_tot_vec = np.sum(y_tot_mat, axis=0)\n",
    "    z_tot_vec = np.sum(z_tot_mat, axis=0)\n",
    "\n",
    "    # Compute nu_y and nu_z using Gamma_vec\n",
    "    nu_y = -np.sum(Gamma_vec * y_tot_vec**2)\n",
    "    nu_z = np.sum(Gamma_vec * z_tot_vec**2)\n",
    "\n",
    "    if separate: return np.real(1j*nu_y/2), np.real(1j*nu_z/2)\n",
    "    else: return np.real(1j*nu_y/2 + 1j*nu_z/2)\n",
    "    \n",
    "\n",
    "def get_xy_nu_helper(p, separate=False, negate=False, force_normal=False):\n",
    "    bitstrings = gen_all_bitstrings(4*p+1)\n",
    "\n",
    "    def get_expectation(params):\n",
    "        gamma_y= params[:p]\n",
    "        gamma_z = params[p:2*p]\n",
    "        beta = params[2*p:]\n",
    "        beta = np.concatenate((beta, np.zeros(1)))\n",
    "        if force_normal:\n",
    "            gamma_y = np.abs(gamma_y)\n",
    "            gamma_z = -np.abs(gamma_z)\n",
    "            beta = np.abs(beta)\n",
    "        return (1-2*negate) * get_xy_nu(p, gamma_y, gamma_z, beta, bitstrings, separate=separate)\n",
    "\n",
    "    return get_expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $MC$ Ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_ps = [1,2,3,4,5,6,7]\n",
    "mc_best_xs = []\n",
    "mc_best_nus = []\n",
    "\n",
    "coeffs= [-1,-1]\n",
    "\n",
    "for p in mc_ps:\n",
    "    trials=p**2\n",
    "    print(f'p={p}')\n",
    "    cost_fn = get_mc_nu_helper(p, negate=True) \n",
    "    best_nu, best_x = 0, np.zeros(2*p)\n",
    "    for trial in tqdm(range(trials)):\n",
    "        init = (np.random.random(2*p))/2-(np.random.random(2*p))/2\n",
    "        res = minimize(cost_fn, init, method='bfgs', options={'gtol':1e-4})\n",
    "        if -res.fun > best_nu:\n",
    "            best_nu = -res.fun\n",
    "            print(f' v_p={np.round(best_nu,6)}, x={np.round(res.x,4)}')\n",
    "            best_x = res.x\n",
    "    mc_best_xs.append(best_x)\n",
    "    mc_best_nus.append(best_nu)\n",
    "    print(f'FINAL p={p}, v_p={np.round(best_nu,6)}, x={np.round(best_x,4)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_large_ps = [8,9,10]\n",
    "mc_large_best_xs = []\n",
    "mc_large_best_nus = []\n",
    "\n",
    "coeffs= [-1,-1]\n",
    "\n",
    "for p in mc_large_ps:\n",
    "    cost_fn = get_mc_nu_helper(p, negate=True) \n",
    "    init = np.concatenate((stretch_array(mc_best_xs[-1][:p-1], p), stretch_array(mc_best_xs[-1][p-1:], p)))\n",
    "    res = minimize(cost_fn, init, method='bfgs', options={'gtol':1e-4})\n",
    "    mc_best_xs.append(res.x)\n",
    "    mc_best_nus.append(-res.fun)\n",
    "    print(f'FINAL p={p}, v_p={np.round(-res.fun,6)}, x={np.round(res.x,4)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/mc_best_nus.pickle', 'wb') as handle:\n",
    "    pickle.dump(mc_best_nus, handle)\n",
    "with open('data/mc_best_xs.pickle', 'wb') as handle:\n",
    "    pickle.dump(mc_best_xs, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/mc_best_nus.pickle', 'rb') as handle:\n",
    "    mc_best_nus = pickle.load(handle)\n",
    "with open('data/mc_best_xs.pickle', 'rb') as handle:\n",
    "    mc_best_xs = pickle.load(handle)\n",
    "\n",
    "print(mc_best_nus)\n",
    "print(mc_best_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_nus_last_gamma_only = []\n",
    "for p in [2,3,4,5,6,7,8,9,10]:\n",
    "    cost_fn = get_mc_nu_last_gamma_helper(p, sk_angles[p-1][0], sk_angles[p-1][1], separate=False, negate=True)\n",
    "    res = minimize(cost_fn, np.random.random(1))\n",
    "    print(p, res.x, -res.fun)\n",
    "    best_nus_last_gamma_only.append(-res.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_energies_farhi = [.3033, .4075, .4726, .5157, .5476, .5721, .5915, 0.6073, 0.6203, 0.6314]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in [2,3,4,5,6,7,8,9,10]:\n",
    "    print(f'p={p}: full optimized nu={np.round(mc_best_nus[p-1],4)}, last gamma optimized nu={np.round(best_nus_last_gamma_only[p-2],4)}, mc best nu at (p-1)={mc_energies_farhi[p-2]}', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/mc_last_gamma_best_nus.pickle', 'wb') as handle:\n",
    "    pickle.dump(best_nus_last_gamma_only, handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $XY$ ansatz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_ps = [2,3,4]\n",
    "xy_best_xs = []\n",
    "xy_best_nus = []\n",
    "coeffs= [-1,-1]\n",
    "trials = 50\n",
    "for p in xy_ps:\n",
    "    print(f'p={p}')\n",
    "    cost_fn = get_xy_nu_helper(p, negate=True) \n",
    "    best_nu, best_x = 0, np.zeros(3*p)\n",
    "    for trial in tqdm(range(trials)):\n",
    "        init = (np.random.random(3*p))-(np.random.random(3*p))\n",
    "        res = minimize(cost_fn, init, method='bfgs', options={'gtol':1e-4})\n",
    "        if -res.fun > best_nu:\n",
    "            best_nu = -res.fun\n",
    "            print(f' v_p={np.round(best_nu,6)}, x={np.round(res.x,4)}')\n",
    "            best_x = res.x\n",
    "    xy_best_xs.append(best_x)\n",
    "    xy_best_nus.append(best_nu)\n",
    "    print(f'FINAL p={p}, v_p={np.round(best_nu,6)}, x={np.round(best_x,4)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_ps = [4]\n",
    "xy_best_xs = []\n",
    "xy_best_nus = []\n",
    "coeffs= [-1,-1]\n",
    "\n",
    "for p in xy_ps:\n",
    "    trials = 10\n",
    "    print(f'p={p}')\n",
    "    cost_fn = get_xy_nu_helper(p, negate=True) \n",
    "    best_nu, best_x = 0, np.zeros(3*p)\n",
    "    for trial in tqdm(range(trials)):\n",
    "        init = (np.random.random(3*p))/2-(np.random.random(3*p))/2\n",
    "        res = minimize(cost_fn, init, method='bfgs', options={'gtol':1e-4})\n",
    "        if -res.fun > best_nu:\n",
    "            best_nu = -res.fun\n",
    "            print(f' v_p={np.round(best_nu,6)}, x={np.round(res.x,4)}')\n",
    "            best_x = res.x\n",
    "    xy_best_xs.append(best_x)\n",
    "    xy_best_nus.append(best_nu)\n",
    "    print(f'FINAL p={p}, v_p={np.round(best_nu,6)}, x={np.round(best_x,4)}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/xy_best_nus.pickle', 'wb') as handle:\n",
    "    pickle.dump(xy_best_nus, handle)\n",
    "with open('data/xy_best_xs.pickle', 'wb') as handle:\n",
    "    pickle.dump(xy_best_xs, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/xy_best_nus.pickle', 'rb') as handle:\n",
    "    xy_best_nus = pickle.load(handle)\n",
    "with open('data/xy_best_xs.pickle', 'rb') as handle:\n",
    "    xy_best_xs = pickle.load(handle)\n",
    "\n",
    "xy_best_nus, xy_best_xs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing agreement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing YZ with 0 gamma_y equivalence with MC\n",
    "import numpy as np\n",
    "def test_mc_and_xy_equal(p, d=np.inf, rtol=.01):\n",
    "\n",
    "    mc_cost_fn = get_mc_nu_helper(p, separate=True)\n",
    "    xy_cost_fn = get_xy_nu_helper(p, separate=True)\n",
    "    #random angles\n",
    "    angles = np.random.random(2*p)\n",
    "    random_mc = mc_cost_fn(angles)\n",
    "    random_xy = xy_cost_fn(np.concatenate((np.zeros(p), angles)))\n",
    "    random_rdif = np.round(np.sum(np.abs(np.array([random_mc])-np.array([random_xy])))/np.sum(np.abs(random_mc)),4)\n",
    "    if np.allclose(random_mc, random_xy, rtol=rtol): \n",
    "        print(f'passed random: mc={np.round(random_mc,6)}, xy={np.round(random_xy,6)}, rdif={random_rdif}, angles={angles}')\n",
    "    else:\n",
    "        print(f'failed random: mc={np.round(random_mc,6)}, xy={np.round(random_xy,6)}, rdif={random_rdif}')\n",
    "    return\n",
    "\n",
    "for p in [1,2,3,4]:\n",
    "    print(f'p={p}')\n",
    "    test_mc_and_xy_equal(p, d=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finite $D$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $MC$ ansatz implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mc_gamma_vec(gamma):\n",
    "    return  np.concatenate((gamma, np.array([0]), -gamma[::-1]))\n",
    "\n",
    "def get_mc_gamma_dp_matrix(gamma, bitstrings):\n",
    "    gamma_vec = get_mc_gamma_vec(gamma) \n",
    "    # Compute the element-wise product and sum (dot products) for all pairs using matrix multiplication\n",
    "    bs_product_matrix = np.dot(bitstrings * gamma_vec, bitstrings.T)\n",
    "    return bs_product_matrix\n",
    "\n",
    "def get_mc_Hps(p, gamma_dp_matrix, fas, d):\n",
    "    bs_size = 2 * p + 1\n",
    "    H_prev = np.ones(2**bs_size, dtype=complex)\n",
    "    for _ in range(p):\n",
    "        cos_matrix = np.cos((1 / np.sqrt(d)) * gamma_dp_matrix)\n",
    "        total_matrix = fas * H_prev * cos_matrix\n",
    "        H_new = np.sum(total_matrix, axis=1) **d\n",
    "        H_prev = H_new \n",
    "    return H_new\n",
    "\n",
    "\n",
    "def get_mc_expectation_helper(p, separate=False, d=None, coeffs=np.ones(3)):\n",
    "    bitstrings = gen_all_bitstrings(2*p+1)\n",
    "\n",
    "    def get_expectation(params):\n",
    "        gamma = params[:p]\n",
    "        beta = params[p:]\n",
    "        assert len(gamma) == p\n",
    "        assert len(beta) == p\n",
    "\n",
    "        fas = get_mc_f_beta(p, bitstrings, beta)\n",
    "        fpas = get_mc_f_beta(p, bitstrings, beta, get_f_prime=True)\n",
    "        \n",
    "        gamma_dp_matrix = get_mc_gamma_dp_matrix(gamma, bitstrings)\n",
    "        gamma_inside_matrix = (1 / np.sqrt(d)) * gamma_dp_matrix\n",
    "        Hp = get_mc_Hps(p, gamma_dp_matrix,  fas, d)\n",
    "        \n",
    "        bs1_p = bitstrings[:, p]\n",
    "        bs2_p = bitstrings[:, p].reshape(-1, 1)\n",
    "        \n",
    "        fas_outer = fas[:, np.newaxis] * fas\n",
    "        fpas_outer = fpas[:, np.newaxis] * fpas\n",
    "        Hp_outer = Hp[:, np.newaxis] * Hp\n",
    "        \n",
    "        sin_gamma_inside_matrix = np.sin(gamma_inside_matrix)\n",
    "        cos_gamma_inside_matrix = np.cos(gamma_inside_matrix)\n",
    "        \n",
    "        totalXX = coeffs[0] * np.sum(fpas_outer * cos_gamma_inside_matrix * Hp_outer)\n",
    "        totalYY = coeffs[1] * np.sum((-1j) * bs1_p * bs2_p * fpas_outer * sin_gamma_inside_matrix * Hp_outer)\n",
    "        totalZZ = coeffs[2] * np.sum(1j * bs1_p * bs2_p * fas_outer * sin_gamma_inside_matrix * Hp_outer)\n",
    "        \n",
    "        if separate: \n",
    "            return np.array([np.real(totalXX), np.real(totalYY), np.real(totalZZ)])\n",
    "        \n",
    "        else:\n",
    "            return  np.real(totalXX + totalYY + totalZZ)\n",
    "\n",
    "    return get_expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "see scaling with p, convergence to something?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=[1,2,3,4,5]\n",
    "ds=[1,2]\n",
    "best_Es_qmc, best_Es_epr, best_Es_xy = np.zeros((len(ds), len(ps))), np.zeros((len(ds), len(ps))), np.zeros((len(ds), len(ps)))\n",
    "all_best_xs_qmc, all_best_xs_epr, all_best_xs_xy = [], [], []\n",
    "for d_idx, d in enumerate(ds):\n",
    "    print(f'd={d}')\n",
    "    d_best_xs_qmc, d_best_xs_epr, d_best_xs_xy = [], [], []\n",
    "    for p_idx, p in enumerate(ps):\n",
    "        print(f'p={p}')\n",
    "        qmc_cost_fn = get_mc_expectation_helper(p, separate=False, d=d, coeffs=np.array([1,1,1])) # minimize +XX+YY+ZZ = maximize -XX-YY-ZZ\n",
    "        epr_cost_fn = get_mc_expectation_helper(p, separate=False, d=d, coeffs=np.array([-1,1,-1])) # minimize -XX+YY-ZZ = maximize +XX-YY+ZZ\n",
    "        xy_cost_fn = get_mc_expectation_helper(p, separate=False, d=d, coeffs=np.array([0,1,1])) # minimize +YY+ZZ = maximize -YY-ZZ\n",
    "        best_E_qmc, best_xs_qmc = 0, np.zeros(2*p) \n",
    "        best_E_epr, best_xs_epr = 0, np.zeros(2*p) \n",
    "        best_E_xy, best_xs_xy = 0, np.zeros(2*p) \n",
    "        for _ in range(20):\n",
    "            init = np.random.random(2*p)-np.random.random(2*p)\n",
    "            res_qmc = minimize(qmc_cost_fn, init)\n",
    "            res_epr = minimize(epr_cost_fn, init)\n",
    "            res_xy = minimize(xy_cost_fn, init)\n",
    "            E_qmc = 1/2-res_qmc.fun/2\n",
    "            E_epr = 1/2-res_epr.fun/2\n",
    "            E_xy = 1/2-res_xy.fun/2\n",
    "            if E_qmc > best_E_qmc:\n",
    "                best_E_qmc = E_qmc\n",
    "                best_xs_qmc = res_qmc.x\n",
    "            if E_epr > best_E_epr:\n",
    "                best_E_epr = E_epr\n",
    "                best_xs_epr = res_epr.x\n",
    "            if E_xy > best_E_xy:\n",
    "                best_E_xy = E_xy\n",
    "                best_xs_xy = res_xy.x\n",
    "        print(f'best_E qmc: {best_E_qmc}, best E epr: {best_E_epr}, best E xy: {best_E_xy}')\n",
    "        best_Es_qmc[d_idx, p_idx] = best_E_qmc\n",
    "        best_Es_epr[d_idx, p_idx] = best_E_epr\n",
    "        best_Es_xy[d_idx, p_idx] = best_E_xy\n",
    "        d_best_xs_qmc.append(best_xs_qmc)\n",
    "        d_best_xs_epr.append(best_xs_epr)\n",
    "        d_best_xs_xy.append(best_xs_xy)\n",
    "    all_best_xs_qmc.append(d_best_xs_qmc)\n",
    "    all_best_xs_epr.append(d_best_xs_epr)\n",
    "    all_best_xs_xy.append(d_best_xs_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_best_xs_qmc)\n",
    "print(all_best_xs_epr)\n",
    "print(all_best_xs_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=[1,2,3,4,5]\n",
    "ds=[3,4]\n",
    "best_Es_qmc, best_Es_epr, best_Es_xy = np.zeros((len(ds), len(ps))), np.zeros((len(ds), len(ps))), np.zeros((len(ds), len(ps)))\n",
    "all_best_xs_qmc, all_best_xs_epr, all_best_xs_xy = [], [], []\n",
    "for d_idx, d in enumerate(ds):\n",
    "    print(f'd={d}')\n",
    "    d_best_xs_qmc, d_best_xs_epr, d_best_xs_xy = [], [], []\n",
    "    for p_idx, p in enumerate(ps):\n",
    "        print(f'p={p}')\n",
    "        qmc_cost_fn = get_mc_expectation_helper(p, separate=False, d=d, coeffs=np.array([1,1,1])) # minimize +XX+YY+ZZ = maximize -XX-YY-ZZ\n",
    "        epr_cost_fn = get_mc_expectation_helper(p, separate=False, d=d, coeffs=np.array([-1,1,-1])) # minimize -XX+YY-ZZ = maximize +XX-YY+ZZ\n",
    "        xy_cost_fn = get_mc_expectation_helper(p, separate=False, d=d, coeffs=np.array([0,1,1])) # minimize +YY+ZZ = maximize -YY-ZZ\n",
    "        best_E_qmc, best_xs_qmc = 0, np.zeros(2*p) \n",
    "        best_E_epr, best_xs_epr = 0, np.zeros(2*p) \n",
    "        best_E_xy, best_xs_xy = 0, np.zeros(2*p) \n",
    "        for _ in range(20):\n",
    "            init = np.random.random(2*p)-np.random.random(2*p)\n",
    "            res_qmc = minimize(qmc_cost_fn, init)\n",
    "            res_epr = minimize(epr_cost_fn, init)\n",
    "            res_xy = minimize(xy_cost_fn, init)\n",
    "            E_qmc = 1/2-res_qmc.fun/2\n",
    "            E_epr = 1/2-res_epr.fun/2\n",
    "            E_xy = 1/2-res_xy.fun/2\n",
    "            if E_qmc > best_E_qmc:\n",
    "                best_E_qmc = E_qmc\n",
    "                best_xs_qmc = res_qmc.x\n",
    "            if E_epr > best_E_epr:\n",
    "                best_E_epr = E_epr\n",
    "                best_xs_epr = res_epr.x\n",
    "            if E_xy > best_E_xy:\n",
    "                best_E_xy = E_xy\n",
    "                best_xs_xy = res_xy.x\n",
    "        print(f'best_E qmc: {best_E_qmc}, best E epr: {best_E_epr}, best E xy: {best_E_xy}')\n",
    "        best_Es_qmc[d_idx, p_idx] = best_E_qmc\n",
    "        best_Es_epr[d_idx, p_idx] = best_E_epr\n",
    "        best_Es_xy[d_idx, p_idx] = best_E_xy\n",
    "        d_best_xs_qmc.append(best_xs_qmc)\n",
    "        d_best_xs_epr.append(best_xs_epr)\n",
    "        d_best_xs_xy.append(best_xs_xy)\n",
    "    all_best_xs_qmc.append(d_best_xs_qmc)\n",
    "    all_best_xs_epr.append(d_best_xs_epr)\n",
    "    all_best_xs_xy.append(d_best_xs_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_best_xs_qmc)\n",
    "print(all_best_xs_epr)\n",
    "print(all_best_xs_xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = np.arange(1,6)\n",
    "# Given data\n",
    "\n",
    "y_values = 2*np.log(2) - np.array([.5, 0.8119196015383394 , 0.9117302730070458, 1.0133793462433751,  1.055389329879501])\n",
    "\n",
    "# Fit a linear polynomial to the data (degree 1)\n",
    "coefficients, cov_matrix = np.polyfit(1/ps, y_values, 1, cov=True)\n",
    "polynomial_fit = np.polyval(coefficients, 1/ps)\n",
    "\n",
    "# Extract slope, intercept and their uncertainties (square root of diagonal elements of covariance matrix)\n",
    "slope, intercept = coefficients\n",
    "slope_err, intercept_err = np.sqrt(np.diag(cov_matrix))\n",
    "\n",
    "# Compute R-squared\n",
    "y_pred = np.polyval(coefficients, 1/ps)\n",
    "ss_res = np.sum((y_values - y_pred) ** 2)\n",
    "ss_tot = np.sum((y_values - np.mean(y_values)) ** 2)\n",
    "r_squared = 1 - (ss_res / ss_tot)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1)\n",
    "\n",
    "# Scatter plot with data points\n",
    "ax.plot(1/ps, y_values, 'o--', label=fr'$MC$ ansatz on $H_{{XY}}$', markersize=5, linewidth=.5)\n",
    "\n",
    "# Add the polynomial fit\n",
    "fit_label = fr'Poly fit'\n",
    "ax.plot(1/ps, polynomial_fit, '--', label=fit_label, color='grey')\n",
    "\n",
    "# Display R^2 value\n",
    "ax.text(0.5, 0.8, f'$R^2 = {r_squared:.3f}$', transform=ax.transAxes, fontsize=12)\n",
    "\n",
    "# Set axis labels\n",
    "ax.set_ylabel(r'$2log2-E$', fontsize=13, rotation=90, labelpad=12)\n",
    "ax.set_xlabel(r'$\\frac{1}{p}$', fontsize=14)\n",
    "\n",
    "# Legend and grid\n",
    "ax.legend(loc='lower right', fontsize=11, framealpha=1)\n",
    "#ax.set_xscale('log')\n",
    "#ax.set_yscale('log')\n",
    "ax.grid()\n",
    "\n",
    "# Adjust layout and save the figure\n",
    "plt.tight_layout()\n",
    "#plt.subplots_adjust(bottom=0.15)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(slope, slope_err, intercept, intercept_err, r_squared)\n",
    "print(fr'$2log2-E$ = ({slope:.3e} $\\pm$ {slope_err:.3e})(1/p) + ({intercept:.3e} $\\pm$ {intercept_err:.3e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### $XY$ ansatz implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_xy_H2p_finite_D(p, gamma_dp_matrix, fas, d):\n",
    "    bs_size = 4 * p + 1\n",
    "    H_prev = np.ones(2**bs_size, dtype=complex)\n",
    "    for _ in range(2*p):\n",
    "        cos_matrix = np.cos((1 / np.sqrt(d)) * gamma_dp_matrix)\n",
    "        total_matrix = fas * H_prev * cos_matrix\n",
    "        H_new = np.sum(total_matrix, axis=1) **d\n",
    "        H_prev = H_new \n",
    "    return H_new\n",
    "\n",
    "\n",
    "def get_xy_gamma_dp_matrix(gamma_vec, bitstrings):\n",
    "    return np.dot(bitstrings * gamma_vec, bitstrings.T)\n",
    "\n",
    "def get_xy_expectation_helper(p, separate=False, d=None, coeffs=(1,1,1)):\n",
    "\n",
    "    bitstrings = gen_all_bitstrings(4*p+1)\n",
    "    def get_expectation(params):\n",
    "        gamma_y= params[:p]\n",
    "        gamma_z = params[p:2*p]\n",
    "        beta = params[2*p:]\n",
    "        gamma_vec = np.zeros(4*p+1)\n",
    "        gamma_vec[:2*p:2]=gamma_z\n",
    "        gamma_vec[1:2*p:2]=gamma_y\n",
    "        gamma_vec[4*p-1:2*p:-2]=-gamma_y\n",
    "        gamma_vec[4*p:2*p:-2]=-gamma_z\n",
    "\n",
    "        fas = get_xy_f(p, bitstrings, beta)\n",
    "        fpas = get_xy_f(p, bitstrings, beta, f_prime=True)\n",
    "\n",
    "        gamma_dp_matrix = get_xy_gamma_dp_matrix(gamma_vec, bitstrings)\n",
    "        gamma_inside_matrix = (1 / np.sqrt(d)) * gamma_dp_matrix\n",
    "        H2p = get_xy_H2p_finite_D(p, gamma_dp_matrix, fas, d) # get H^(2p)\n",
    "\n",
    "        bs1_2p = bitstrings[:, 2*p]\n",
    "        bs2_2p = bitstrings[:, 2*p].reshape(-1, 1)\n",
    "        \n",
    "        fas_outer = fas[:, np.newaxis] * fas\n",
    "        fpas_outer = fpas[:, np.newaxis] * fpas\n",
    "        H2p_outer = H2p[:, np.newaxis] * H2p\n",
    "\n",
    "        sin_gamma_inside_matrix = np.sin(gamma_inside_matrix)\n",
    "        cos_gamma_inside_matrix = np.cos(gamma_inside_matrix)\n",
    "        \n",
    "        totalXX = coeffs[0] * np.sum(fpas_outer * cos_gamma_inside_matrix * H2p_outer)\n",
    "        totalYY = coeffs[1] * np.sum((-1j) * bs1_2p * bs2_2p * fpas_outer * sin_gamma_inside_matrix * H2p_outer)\n",
    "        totalZZ = coeffs[2] * np.sum(1j * bs1_2p * bs2_2p * fas_outer * sin_gamma_inside_matrix * H2p_outer)\n",
    "        \n",
    "        if separate: \n",
    "            return np.array([np.real(totalXX), np.real(totalYY), np.real(totalZZ)])\n",
    "        \n",
    "        else:\n",
    "            return  np.real(totalXX + totalYY + totalZZ)\n",
    "\n",
    "    return get_expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing agreement\n",
    "p=2\n",
    "d=2\n",
    "qmc_cost_fn_mc = get_mc_expectation_helper(p, separate=True, d=d, coeffs=np.array([1,1,1])) # minimize +XX+YY+ZZ = maximize -XX-YY-ZZ\n",
    "qmc_cost_fn_xy = get_xy_expectation_helper(p, separate=True, d=d, coeffs=np.array([1,1,1])) # minimize +XX+YY+ZZ = maximize -XX-YY-ZZ\n",
    "print(qmc_cost_fn_mc(np.array([1,.5,1,1])))\n",
    "print(qmc_cost_fn_xy(np.array([0,0,1,.5,1,1]))) # all gamma_y = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=[1,2]\n",
    "ds=[1,2,3,4]\n",
    "best_Es_qmc, best_Es_epr, best_Es_xy = np.zeros((len(ds), len(ps))), np.zeros((len(ds), len(ps))), np.zeros((len(ds), len(ps)))\n",
    "all_best_xs_qmc, all_best_xs_epr, all_best_xs_xy = [], [], []\n",
    "for d_idx, d in enumerate(ds):\n",
    "    print(f'd={d}')\n",
    "    d_best_xs_qmc, d_best_xs_epr, d_best_xs_xy = [], [], []\n",
    "    for p_idx, p in enumerate(ps):\n",
    "        print(f'p={p}')\n",
    "        qmc_cost_fn = get_xy_expectation_helper(p, separate=False, d=d, coeffs=np.array([1,1,1])) # minimize +XX+YY+ZZ = maximize -XX-YY-ZZ\n",
    "        epr_cost_fn = get_xy_expectation_helper(p, separate=False, d=d, coeffs=np.array([-1,1,-1])) # minimize -XX+YY-ZZ = maximize +XX-YY+ZZ\n",
    "        xy_cost_fn = get_xy_expectation_helper(p, separate=False, d=d, coeffs=np.array([0,1,1])) # minimize +YY+ZZ = maximize -YY-ZZ\n",
    "        best_E_qmc, best_xs_qmc = 0, np.zeros(3*p) \n",
    "        best_E_epr, best_xs_epr = 0, np.zeros(3*p) \n",
    "        best_E_xy, best_xs_xy = 0, np.zeros(3*p) \n",
    "        for _ in tqdm(range(100//p**2)): # takes very long to run p=2\n",
    "            init = np.random.random(3*p)-np.random.random(3*p)\n",
    "            res_qmc = minimize(qmc_cost_fn, init)\n",
    "            res_epr = minimize(epr_cost_fn, init)\n",
    "            res_xy = minimize(xy_cost_fn, init)\n",
    "            E_qmc = 1/2-res_qmc.fun/2\n",
    "            E_epr = 1/2-res_epr.fun/2\n",
    "            E_xy = 1/2-res_xy.fun/2\n",
    "            if E_qmc > best_E_qmc:\n",
    "                best_E_qmc = E_qmc\n",
    "                best_xs_qmc = res_qmc.x\n",
    "            if E_epr > best_E_epr:\n",
    "                best_E_epr = E_epr\n",
    "                best_xs_epr = res_epr.x\n",
    "            if E_xy > best_E_xy:\n",
    "                best_E_xy = E_xy\n",
    "                best_xs_xy = res_xy.x\n",
    "        print(f'best E qmc: {best_E_qmc}, best E epr: {best_E_epr}, best E xy: {best_E_xy}')\n",
    "        print(f'best xs qmc: {np.round(best_xs_qmc,6)}, best xs epr: {np.round(best_xs_epr,6)}, best xs xy: {np.round(best_xs_xy, 6)}')\n",
    "        best_Es_qmc[d_idx, p_idx] = best_E_qmc\n",
    "        best_Es_epr[d_idx, p_idx] = best_E_epr\n",
    "        best_Es_xy[d_idx, p_idx] = best_E_xy\n",
    "        d_best_xs_qmc.append(best_xs_qmc)\n",
    "        d_best_xs_epr.append(best_xs_epr)\n",
    "        d_best_xs_xy.append(best_xs_xy)\n",
    "    all_best_xs_qmc.append(d_best_xs_qmc)\n",
    "    all_best_xs_epr.append(d_best_xs_epr)\n",
    "    all_best_xs_xy.append(d_best_xs_xy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit_qaoa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
